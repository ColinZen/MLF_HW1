{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8036ce8a",
   "metadata": {},
   "source": [
    "Imports essential libraries (pandas, numpy, matplotlib, sklearn, scipy, os). Configures matplotlib for plotting and sets global warnings to be ignored. Defines the standard file path for data (features.parquet) and a directory for saving diagnostic results (results/q7_diagnostics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1549d9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import ElasticNet\n",
    "# from sklearn.metrics import r2_score # 不再使用\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# 基础配置\n",
    "plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 数据/结果路径\n",
    "DATA_PATH = \"features.parquet\"\n",
    "RESULTS_DIR = \"results/q7_diagnostics\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbfa133",
   "metadata": {},
   "source": [
    "This function defines the specific Out-of-Sample R-squared ($R^2_{OOS}$) metric required for financial forecasting, based on the methodology of Gu, Kelly, & Xiu (2020). The key feature of this $R^2$ is that the denominator (the measure of total variance, $SST$) is calculated as the sum of squared actual returns ($\\sum y_{true}^2$), rather than the standard sum of squared deviations from the mean. This metric is used to evaluate the economic significance of the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9125def4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_oos_gkx(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    计算 Gu-Kelly-Xiu (2020) 要求的 OOS R²。\n",
    "    分母是 y_true 的平方和（相对于0），而不是相对于均值。\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    \n",
    "    if y_true.shape[0] == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    sse = np.sum((y_true - y_pred)**2)\n",
    "    sst = np.sum(y_true**2) # GKX 关键点：分母是 y^2 的和\n",
    "    \n",
    "    if sst == 0: \n",
    "        return np.nan\n",
    "        \n",
    "    return 1.0 - (sse / sst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3435f515",
   "metadata": {},
   "source": [
    "This function is responsible for robustly loading and cleaning the financial data.\n",
    "\n",
    "It reads the features.parquet file and identifies the feature and target columns.\n",
    "\n",
    "Target Filtering: It filters out any rows where the target variable (ret_excess_t_plus_1) is missing.\n",
    "\n",
    "Two-Stage Feature Imputation (Crucial Fix):\n",
    "\n",
    "Stage 1 (Cross-Sectional Median): It performs the standard practice of monthly cross-sectional median imputation, replacing missing feature values in a given month with that month's median for that feature.\n",
    "\n",
    "Stage 2 (Fallback to Zero): It applies a fallback: any remaining missing values (which only occur if a feature is entirely missing for an entire month, preventing a median calculation) are filled with 0. This fix ensures that the early period data (1957-1974), which contained these \"all-NaN\" months, is retained for training.\n",
    "\n",
    "It returns the cleaned data, features, and target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ab3ad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"加载数据（修正了插值逻辑以处理全NaN月份）\"\"\"\n",
    "    print(\"加载数据...\")\n",
    "    if not os.path.exists(DATA_PATH):\n",
    "        raise FileNotFoundError(f\"数据文件未找到: {DATA_PATH}。请确保 features.parquet 在正确路径。\")\n",
    "    \n",
    "    df = pd.read_parquet(DATA_PATH)\n",
    "    \n",
    "    if 'month' not in df.columns:\n",
    "        raise KeyError(\"数据中未找到 'month' 列，无法继续。\")\n",
    "    df['month'] = pd.to_datetime(df['month'])\n",
    "    \n",
    "    feature_cols = [col for col in df.columns if col.startswith(('c_', 'm_', 'sic_'))]\n",
    "    if 'c_mvel1' not in feature_cols:\n",
    "         warnings.warn(\"警告：未找到市值特征 'c_mvel1'。规模分组分析将失败。\")\n",
    "         \n",
    "    print(f\"特征列数: {len(feature_cols)}\")\n",
    "    \n",
    "    y = df['ret_excess_t_plus_1'].astype(np.float32)\n",
    "    X = df[feature_cols].astype(np.float32)\n",
    "    \n",
    "    # 1. 丢弃没有目标(y)的样本\n",
    "    y_mask = ~y.isnull()\n",
    "    X, y, df = X[y_mask], y[y_mask], df[y_mask]\n",
    "    \n",
    "    # 2. 按月份对特征 X 进行中位数插值\n",
    "    df['month_period'] = df['month'].dt.to_period(\"M\")\n",
    "    print(\"...开始月度中位数插值...\")\n",
    "    X_imputed = X.groupby(df['month_period']).transform(lambda x: x.fillna(x.median()))\n",
    "    print(\"...月度中位数插值完成。\")\n",
    "    \n",
    "    # ### 关键修正 ###\n",
    "    # 如果一个月的所有值都为NaN，则该月的中位数也为NaN，插值失败。\n",
    "    # 我们在这里添加一个“后备”插值，用 0 填充那些仍然为 NaN 的值。\n",
    "    print(\"...开始后备插值 (fillna(0))...\")\n",
    "    X_imputed_fallback = X_imputed.fillna(0)\n",
    "    print(\"...后备插值完成。\")\n",
    "\n",
    "    # 3. 丢弃插值后 X 中仍有缺失值的样本 (现在不应该有)\n",
    "    x_mask = ~X_imputed_fallback.isnull().any(axis=1)\n",
    "    X, y, df = X_imputed_fallback[x_mask], y[x_mask], df[x_mask]\n",
    "    \n",
    "    if len(df) == 0:\n",
    "        raise ValueError(\"数据加载和清洗后，剩余样本为0。请检查数据源或清洗逻辑。\")\n",
    "        \n",
    "    print(f\"数据加载完成，最终有效样本数: {len(df)}\")\n",
    "    return df, X, y, feature_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88dd018",
   "metadata": {},
   "source": [
    "This function trains the baseline Elastic Net model and evaluates its initial performance.Data Splitting: It splits the data into three chronological segments: Training (1957–1974), Validation (1975–1986), and Test (1987–2016).\n",
    "\n",
    "Standardization: It fits a StandardScaler only on the training set and uses it to transform all three sets.\n",
    "\n",
    "Model Training: It trains the baseline Elastic Net model with fixed hyperparameters ($\\alpha=0.5$ and $l1\\_ratio=0.5$).Evaluation: \n",
    "\n",
    "It calculates the  Roos² (using the r2_oos_gkx metric) for both the validation and test sets and prints the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2111aa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_elastic_net(df, X, y):\n",
    "    \"\"\"训练弹性网络模型（作业基准模型），用于后续诊断\"\"\"\n",
    "    print(\"\\n训练弹性网络模型（基准参数：alpha=0.5, l1_ratio=0.5）...\")\n",
    "    \n",
    "    print(f\"数据时间范围: {df['month'].min().date()} 到 {df['month'].max().date()}\")\n",
    "    print(f\"训练集时间范围: 1957-01-01 到 1974-12-31\")\n",
    "    print(f\"验证集时间范围: 1975-01-01 到 1986-12-31\")\n",
    "    print(f\"测试集时间范围: 1987-01-01 到 2016-12-31\")\n",
    "    \n",
    "    # 按作业Q3规则划分数据集\n",
    "    train_mask = (df['month'] >= '1957-01-01') & (df['month'] <= '1974-12-31')\n",
    "    val_mask = (df['month'] >= '1975-01-01') & (df['month'] <= '1986-12-31')\n",
    "    test_mask = (df['month'] >= '1987-01-01') & (df['month'] <= '2016-12-31')\n",
    "    \n",
    "    print(f\"训练集样本数: {train_mask.sum()}\")\n",
    "    print(f\"验证集样本数: {val_mask.sum()}\")\n",
    "    print(f\"测试集样本数: {test_mask.sum()}\")\n",
    "    \n",
    "    if train_mask.sum() == 0:\n",
    "        # 此时如果训练集仍为0，则说明1957-1974的数据在 .parquet 文件中根本不存在\n",
    "        raise ValueError(\"训练集样本为0。即使经过插值修正，数据仍然缺失。\\n\"\n",
    "                         \"请确认您的 features.parquet 文件 *物理上* 包含 1957-1974 年的数据。\")\n",
    "    \n",
    "    X_train, y_train = X[train_mask], y[train_mask]\n",
    "    X_val, y_val = X[val_mask], y[val_mask]\n",
    "    X_test, y_test = X[test_mask], y[test_mask]\n",
    "    \n",
    "    # 特征标准化\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # 训练基准弹性网络模型\n",
    "    en_baseline = ElasticNet(\n",
    "        alpha=0.5, \n",
    "        l1_ratio=0.5, \n",
    "        random_state=42,\n",
    "        max_iter=10000 \n",
    "    )\n",
    "    en_baseline.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # 计算各集预测值与残差\n",
    "    y_val_pred = en_baseline.predict(X_val_scaled)\n",
    "    y_test_pred = en_baseline.predict(X_test_scaled)\n",
    "    resid_val = y_val - y_val_pred\n",
    "    resid_test = y_test - y_test_pred\n",
    "    \n",
    "    val_r2 = r2_oos_gkx(y_val, y_val_pred)\n",
    "    test_r2 = r2_oos_gkx(y_test, y_test_pred)\n",
    "    print(f\"验证集 OOS R² (GKX): {val_r2:.6f}\")\n",
    "    print(f\"测试集 OOS R² (GKX): {test_r2:.6f}\")\n",
    "    \n",
    "    return (en_baseline, scaler, \n",
    "            X_val_scaled, X_test_scaled, \n",
    "            y_val, y_test, \n",
    "            y_val_pred, y_test_pred, \n",
    "            resid_val, resid_test, \n",
    "            df[val_mask], df[test_mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8e8bbb",
   "metadata": {},
   "source": [
    "This function executes the first core diagnostic check: analyzing the statistical properties of the Test Set residuals (resid_test).\n",
    "\n",
    "It calculates and prints key statistics such as the residual mean (ideally zero), standard deviation, skewness, and kurtosis.\n",
    "\n",
    "It performs the Shapiro-Wilk test on a sample of 5,000 residuals to formally test the assumption of normality.\n",
    "\n",
    "It calculates and reports the percentage of residuals that are considered extreme outliers based on the 1.5 times Interquartile Range (IQR) rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35823859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_residual_distribution(residuals):\n",
    "    \"\"\"残差分布分析（Q7核心诊断1）\"\"\"\n",
    "    print(\"\\n=== 残差分布分析 ===\")\n",
    "    \n",
    "    mean_res = residuals.mean()\n",
    "    std_res = residuals.std()\n",
    "    skewness = stats.skew(residuals)\n",
    "    kurtosis = stats.kurtosis(residuals) # (费雪定义, 0为正态)\n",
    "    \n",
    "    print(f\"残差均值: {mean_res:.6f}（理想≈0）\")\n",
    "    print(f\"残差标准差: {std_res:.6f}\")\n",
    "    print(f\"偏度: {skewness:.4f}（理想≈0）\")\n",
    "    print(f\"峰度 (Fisher): {kurtosis:.4f}（理想≈0）\")\n",
    "    \n",
    "    sample_residuals = residuals.sample(min(5000, len(residuals)), random_state=42)\n",
    "    shapiro_stat, shapiro_p = stats.shapiro(sample_residuals)\n",
    "    print(f\"Shapiro-Wilk检验 (N=5000): 统计量={shapiro_stat:.4f}, p值={shapiro_p:.6f}（>0.05为正态）\")\n",
    "    \n",
    "    Q1, Q3 = np.percentile(residuals, [25, 75])\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = residuals[(residuals < Q1 - 1.5*IQR) | (residuals > Q3 + 1.5*IQR)]\n",
    "    print(f\"异常值占比: {len(outliers)/len(residuals)*100:.2f}%\")\n",
    "    \n",
    "    return {\n",
    "        'mean': mean_res, 'std': std_res, 'skewness': skewness, \n",
    "        'kurtosis': kurtosis, 'shapiro_p': shapiro_p, 'outlier_ratio': len(outliers)/len(residuals)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39c5571",
   "metadata": {},
   "source": [
    "This function creates a visualization summary for the residual analysis performed in the previous block.It generates a $2 \\times 2$ figure containing four standard diagnostic plots:A histogram of the residuals compared to a fitted Normal distribution.A Q-Q plot to visually assess normality against the theoretical quantiles.A scatter plot of residuals versus predicted values, used to check for heteroscedasticity (non-constant variance).A box plot of the residuals.The resulting figure is saved as residual_diagnostics.png."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c46e667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_residual_diagnostics(residuals, y_test, y_test_pred):\n",
    "    \"\"\"绘制残差诊断图（Q7核心诊断1的可视化）\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle(\"Elastic Net: Residual Distribution Diagnostics (Test Set)\", fontsize=14, fontweight=\"bold\")\n",
    "    \n",
    "    # 1. 残差直方图 + 正态分布对比\n",
    "    ax1 = axes[0, 0]\n",
    "    iqr = np.percentile(residuals, 75) - np.percentile(residuals, 25)\n",
    "    bin_width = 2 * iqr / (len(residuals)**(1/3))\n",
    "    bins = int((residuals.max() - residuals.min()) / bin_width) if bin_width > 0 else 50\n",
    "    bins = min(bins, 200) # 限制最大 bins 数量\n",
    "    \n",
    "    ax1.hist(residuals, bins=bins, density=True, alpha=0.7, color='skyblue', label='Residuals')\n",
    "    mu, sigma = residuals.mean(), residuals.std()\n",
    "    x_norm = np.linspace(mu - 4*sigma, mu + 4*sigma, 100)\n",
    "    y_norm = stats.norm.pdf(x_norm, mu, sigma)\n",
    "    ax1.plot(x_norm, y_norm, 'r--', linewidth=2, label=f'Normal(N={mu:.4f}, σ={sigma:.4f})')\n",
    "    ax1.set_xlabel('Residuals')\n",
    "    ax1.set_ylabel('Density')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_xlim(mu - 4*sigma, mu + 4*sigma) \n",
    "    \n",
    "    # 2. Q-Q图\n",
    "    ax2 = axes[0, 1]\n",
    "    stats.probplot(residuals.sample(min(5000, len(residuals)), random_state=42), dist=\"norm\", plot=ax2)\n",
    "    ax2.set_title('Q-Q Plot (Normality Test)')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. 残差 vs 预测值\n",
    "    ax3 = axes[1, 0]\n",
    "    ax3.scatter(y_test_pred, residuals, alpha=0.1, s=1) \n",
    "    ax3.axhline(y=0, color='r', linestyle='--', alpha=0.8)\n",
    "    ax3.set_xlabel('Predicted Excess Returns')\n",
    "    ax3.set_ylabel('Residuals')\n",
    "    ax3.set_title('Residuals vs Predicted Values (Heteroscedasticity Check)')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. 残差箱线图\n",
    "    ax4 = axes[1, 1]\n",
    "    box_plot = ax4.boxplot(residuals, patch_artist=True, showfliers=False) \n",
    "    box_plot['boxes'][0].set_facecolor('lightblue')\n",
    "    ax4.set_ylabel('Residuals')\n",
    "    ax4.set_title('Box Plot (Outlier Detection - Fliers Hidden)')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.savefig(f\"{RESULTS_DIR}/residual_diagnostics.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"\\n残差诊断图已保存至 {RESULTS_DIR}/residual_diagnostics.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537ee772",
   "metadata": {},
   "source": [
    "This function performs the second core diagnostic, assessing whether the model's performance varies across different firm sizes.\n",
    "\n",
    "It uses the lagged market equity feature (c_mvel1) to create five size-based quantiles (buckets) per month in the test set.\n",
    "\n",
    "It then calculates the key performance metrics (OOS R² and residual statistics) separately for each of the five size buckets.\n",
    "\n",
    "The results are printed, and a series of histograms comparing the residual distributions across the buckets are plotted and saved as size_bucket_analysis.png."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "368835e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_size_buckets(df_test, residuals, y_test, y_test_pred):\n",
    "    \"\"\"按公司规模分组分析（Q7核心诊断2）\"\"\"\n",
    "    print(\"\\n=== 按公司规模分组分析 ===\")\n",
    "    \n",
    "    if 'c_mvel1' in df_test.columns:\n",
    "        df_test_copy = df_test.copy()\n",
    "        \n",
    "        residuals_series = pd.Series(residuals, index=df_test_copy.index)\n",
    "        y_test_series = pd.Series(y_test, index=df_test_copy.index)\n",
    "        y_test_pred_series = pd.Series(y_test_pred, index=df_test_copy.index)\n",
    "        \n",
    "        if not df_test_copy.index.is_unique:\n",
    "             print(\"警告：df_test 索引不唯一，重置索引以进行规模分组。\")\n",
    "             df_test_copy = df_test_copy.reset_index(drop=True)\n",
    "             residuals_series = residuals_series.reset_index(drop=True)\n",
    "             y_test_series = y_test_series.reset_index(drop=True)\n",
    "             y_test_pred_series = y_test_pred_series.reset_index(drop=True)\n",
    "\n",
    "        df_test_copy['size_bucket'] = df_test_copy.groupby(df_test_copy['month_period'])['c_mvel1'].transform(\n",
    "            lambda x: pd.qcut(x, q=5, labels=['1_Small', '2_Small-Mid', '3_Mid', '4_Mid-Large', '5_Large'], duplicates='drop')\n",
    "        )\n",
    "        \n",
    "        size_metrics_list = []\n",
    "        for bucket_name, group in df_test_copy.groupby('size_bucket'):\n",
    "            group_indices = group.index\n",
    "            \n",
    "            oos_r2 = r2_oos_gkx(\n",
    "                y_test_series[group_indices], \n",
    "                y_test_pred_series[group_indices]\n",
    "            )\n",
    "            \n",
    "            size_metrics_list.append({\n",
    "                'size_bucket': bucket_name,\n",
    "                'sample_count': len(group),\n",
    "                'oos_r2_gkx': oos_r2,\n",
    "                'resid_mean': residuals_series[group_indices].mean(),\n",
    "                'resid_std': residuals_series[group_indices].std()\n",
    "            })\n",
    "        \n",
    "        size_metrics = pd.DataFrame(size_metrics_list).set_index('size_bucket').round(6)\n",
    "        \n",
    "        print(\"规模分组性能指标：\")\n",
    "        print(size_metrics.to_string())\n",
    "        \n",
    "        # 绘制分组残差分布对比图\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        for i, bucket_name in enumerate(size_metrics.index):\n",
    "            plt.subplot(1, 5, i+1)\n",
    "            group_resid = residuals_series[df_test_copy['size_bucket'] == bucket_name]\n",
    "            \n",
    "            if group_resid.empty:\n",
    "                continue\n",
    "\n",
    "            plt.hist(group_resid, bins=30, alpha=0.7, density=True, color=f'C{i}')\n",
    "            plt.xlabel('Residuals')\n",
    "            if i == 0:\n",
    "                plt.ylabel('Density')\n",
    "            plt.title(f'{bucket_name}\\nR²={size_metrics.loc[bucket_name, \"oos_r2_gkx\"]:.4f}')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.xlim(np.percentile(residuals, 1), np.percentile(residuals, 99))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{RESULTS_DIR}/size_bucket_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"规模分组分析图已保存至 {RESULTS_DIR}/size_bucket_analysis.png\")\n",
    "    else:\n",
    "        warnings.warn(\"未找到市值特征（c_mvel1），跳过规模分组分析\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e961cd7b",
   "metadata": {},
   "source": [
    "This function performs the third core diagnostic, checking for signs of overfitting by comparing the model's stability between the Validation and Test sets.\n",
    "\n",
    "It calculates the 36-month rolling OOS R² time series for both the Validation period and the Test period.\n",
    "\n",
    "It compares the average rolling R² from both periods. A difference greater than 0.002 (0.2%) between the Validation and Test averages is flagged as a sign of potential overfitting.\n",
    "\n",
    "The rolling R² time series are plotted together on a single graph and saved as overfit_test.png."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97205ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_overfit(resid_val, y_val, resid_test, y_test, df_val, df_test):\n",
    "    \"\"\"过拟合特征检验（Q7核心诊断3：Val vs Test性能对比）\"\"\"\n",
    "    print(\"\\n=== 过拟合特征检验（Val vs Test） ===\")\n",
    "    \n",
    "    y_val_series = pd.Series(y_val, index=df_val.index)\n",
    "    y_test_series = pd.Series(y_test, index=df_test.index)\n",
    "    resid_val_series = pd.Series(resid_val, index=df_val.index)\n",
    "    resid_test_series = pd.Series(resid_test, index=df_test.index)\n",
    "\n",
    "    def calculate_rolling_r2(residuals_s, y_true_s, df, window=36):\n",
    "        if not residuals_s.index.equals(df.index) or not y_true_s.index.equals(df.index):\n",
    "             print(\"警告(check_overfit): 索引不对齐，重置索引。\")\n",
    "             df = df.reset_index(drop=True)\n",
    "             residuals_s = residuals_s.reset_index(drop=True)\n",
    "             y_true_s = y_true_s.reset_index(drop=True)\n",
    "             \n",
    "        monthly_resid_sq_sum = residuals_s.groupby(df['month_period']).apply(lambda x: (x**2).sum())\n",
    "        monthly_y_sq_sum = y_true_s.groupby(df['month_period']).apply(lambda x: (x**2).sum())\n",
    "        \n",
    "        monthly_agg = pd.DataFrame({\n",
    "            'resid_sq_sum': monthly_resid_sq_sum,\n",
    "            'y_sq_sum': monthly_y_sq_sum\n",
    "        })\n",
    "        \n",
    "        monthly_agg['month_date'] = df.groupby(df['month_period'])['month'].first()\n",
    "        \n",
    "        monthly_agg['rolling_resid_sq'] = monthly_agg['resid_sq_sum'].rolling(window=window).sum()\n",
    "        monthly_agg['rolling_y_sq'] = monthly_agg['y_sq_sum'].rolling(window=window).sum()\n",
    "        \n",
    "        monthly_agg['rolling_r2'] = 1 - (monthly_agg['rolling_resid_sq'] / monthly_agg['rolling_y_sq'].replace(0, np.nan))\n",
    "        return monthly_agg.dropna(subset=['rolling_r2'])\n",
    "    \n",
    "    val_rolling = calculate_rolling_r2(resid_val_series, y_val_series, df_val)\n",
    "    test_rolling = calculate_rolling_r2(resid_test_series, y_test_series, df_test)\n",
    "    \n",
    "    val_avg_r2 = val_rolling['rolling_r2'].mean()\n",
    "    test_avg_r2 = test_rolling['rolling_r2'].mean()\n",
    "    r2_diff = val_avg_r2 - test_avg_r2\n",
    "    overfit_flag = \"是\" if r2_diff > 0.002 else \"否\" \n",
    "    \n",
    "    print(f\"验证集36个月滚动平均R²: {val_avg_r2:.6f}\")\n",
    "    print(f\"测试集36个月滚动平均R²: {test_avg_r2:.6f}\")\n",
    "    print(f\"Val - Test R²差值: {r2_diff:.6f}\")\n",
    "    print(f\"是否过拟合: {overfit_flag}（差值>0.2%为过拟合）\")\n",
    "    \n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(val_rolling['month_date'], val_rolling['rolling_r2']*100, \n",
    "             label=f'Validation Set (1975-1986, Avg: {val_avg_r2:.4f})', color='blue', linewidth=2)\n",
    "    plt.plot(test_rolling['month_date'], test_rolling['rolling_r2']*100, \n",
    "             label=f'Test Set (1987-2016, Avg: {test_avg_r2:.4f})', color='orange', linewidth=2, linestyle='--')\n",
    "    plt.axhline(y=0, color='red', linestyle=':', linewidth=1.5, label='R²=0 Baseline')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('36-Month Rolling OOS R² (GKX) [%]')\n",
    "    plt.title('Overfitting Test: Val vs Test Rolling R²')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.text(0.02, 0.95, f\"Overfit Check: {overfit_flag}\\n(Diff = {r2_diff:.4f})\",\n",
    "             transform=plt.gca().transAxes, bbox=dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.8),\n",
    "             verticalalignment=\"top\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{RESULTS_DIR}/overfit_test.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"过拟合检验图已保存至 {RESULTS_DIR}/overfit_test.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a396b6fc",
   "metadata": {},
   "source": [
    "This function performs the final core task of hyperparameter tuning for the Elastic Net model.\n",
    "\n",
    "It defines a set of candidate $\\alpha$ values (regularization strengths) while fixing the $l1\\_ratio$ to 0.5.It trains a separate Elastic Net model for each $\\alpha$ on the Training set.\n",
    "\n",
    "Model Selection: It selects the best set of parameters based on the highest GKX OOS R² achieved on the Validation set.\n",
    "\n",
    "It prints the performance of the optimal model on both the Validation and Test sets and saves the complete tuning results to a CSV file (elastic_net_tuning_results.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3de7af7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning_elastic_net(df, X, y, scaler):\n",
    "    \"\"\"弹性网络调优尝试（Q7核心任务4）\"\"\"\n",
    "    print(\"\\n=== 弹性网络调优尝试 ===\")\n",
    "    \n",
    "    train_mask = (df['month'] >= '1957-01-01') & (df['month'] <= '1974-12-31')\n",
    "    val_mask = (df['month'] >= '1975-01-01') & (df['month'] <= '1986-12-31')\n",
    "    test_mask = (df['month'] >= '1987-01-01') & (df['month'] <= '2016-12-31')\n",
    "    \n",
    "    X_train, y_train = X[train_mask], y[train_mask]\n",
    "    X_val, y_val = X[val_mask], y[val_mask]\n",
    "    X_test, y_test = X[test_mask], y[test_mask]\n",
    "    \n",
    "    # 标准化\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    alpha_candidates = [0.01, 0.1, 0.5, 1.0, 5.0] \n",
    "    l1_ratio_fixed = 0.5\n",
    "    tuning_results = []\n",
    "    \n",
    "    print(f\"调优参数: l1_ratio={l1_ratio_fixed} (固定), alpha 候选: {alpha_candidates}\")\n",
    "    \n",
    "    for alpha in alpha_candidates:\n",
    "        en_tuned = ElasticNet(\n",
    "            alpha=alpha,\n",
    "            l1_ratio=l1_ratio_fixed,\n",
    "            random_state=42,\n",
    "            max_iter=10000\n",
    "        )\n",
    "        en_tuned.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        y_val_pred = en_tuned.predict(X_val_scaled)\n",
    "        y_test_pred = en_tuned.predict(X_test_scaled)\n",
    "        \n",
    "        val_r2 = r2_oos_gkx(y_val, y_val_pred)\n",
    "        test_r2 = r2_oos_gkx(y_test, y_test_pred)\n",
    "        test_resid_std = (y_test - y_test_pred).std()\n",
    "        \n",
    "        tuning_results.append({\n",
    "            'alpha': alpha,\n",
    "            'l1_ratio': l1_ratio_fixed,\n",
    "            'val_r2_gkx': val_r2,\n",
    "            'test_r2_gkx': test_r2,\n",
    "            'test_resid_std': test_resid_std\n",
    "        })\n",
    "        \n",
    "        print(f\"  alpha={alpha:5.2f}: Val R²={val_r2:.6f}, Test R²={test_r2:.6f}, 残差标准差={test_resid_std:.6f}\")\n",
    "    \n",
    "    tuning_df = pd.DataFrame(tuning_results).round(6)\n",
    "    \n",
    "    best_idx = tuning_df['val_r2_gkx'].idxmax()\n",
    "    best_params = tuning_df.iloc[best_idx]\n",
    "    \n",
    "    print(f\"\\n最佳调优参数 (基于 Val R²): alpha={best_params['alpha']}, l1_ratio={best_params['l1_ratio']}\")\n",
    "    print(f\"最佳参数的 *验证集* 性能: Val R²={best_params['val_r2_gkx']:.6f}\")\n",
    "    print(f\"最佳参数的 *测试集* 性能: Test R²={best_params['test_r2_gkx']:.6f}, 残差标准差={best_params['test_resid_std']:.6f}\")\n",
    "    \n",
    "    tuning_df.to_csv(f\"{RESULTS_DIR}/elastic_net_tuning_results.csv\", index=False)\n",
    "    print(f\"调优结果已保存至 {RESULTS_DIR}/elastic_net_tuning_results.csv\")\n",
    "    \n",
    "    return tuning_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "397a5fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载数据...\n",
      "特征列数: 176\n",
      "...开始月度中位数插值...\n",
      "...月度中位数插值完成。\n",
      "...开始后备插值 (fillna(0))...\n",
      "...后备插值完成。\n",
      "数据加载完成，最终有效样本数: 4320692\n"
     ]
    }
   ],
   "source": [
    "df, X, y, feature_cols = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9322daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "训练弹性网络模型（基准参数：alpha=0.5, l1_ratio=0.5）...\n",
      "数据时间范围: 1957-01-31 到 2021-11-30\n",
      "训练集时间范围: 1957-01-01 到 1974-12-31\n",
      "验证集时间范围: 1975-01-01 到 1986-12-31\n",
      "测试集时间范围: 1987-01-01 到 2016-12-31\n",
      "训练集样本数: 501162\n",
      "验证集样本数: 812160\n",
      "测试集样本数: 2628130\n",
      "验证集 OOS R² (GKX): -0.000548\n",
      "测试集 OOS R² (GKX): -0.000262\n"
     ]
    }
   ],
   "source": [
    "# 2. 训练基准弹性网络模型\n",
    "(en_baseline, scaler, \n",
    "X_val_scaled, X_test_scaled, \n",
    "y_val, y_test, \n",
    "y_val_pred, y_test_pred, \n",
    "resid_val, resid_test, \n",
    "df_val, df_test) = train_elastic_net(df, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed371147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 残差分布分析 ===\n",
      "残差均值: 0.007542（理想≈0）\n",
      "残差标准差: 0.179207\n",
      "偏度: 7.4210（理想≈0）\n",
      "峰度 (Fisher): 386.5944（理想≈0）\n",
      "Shapiro-Wilk检验 (N=5000): 统计量=0.6654, p值=0.000000（>0.05为正态）\n",
      "异常值占比: 9.70%\n",
      "\n",
      "残差诊断图已保存至 results/q7_diagnostics/residual_diagnostics.png\n"
     ]
    }
   ],
   "source": [
    "residual_stats = analyze_residual_distribution(resid_test)\n",
    "plot_residual_diagnostics(resid_test, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "060ca88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 按公司规模分组分析 ===\n",
      "规模分组性能指标：\n",
      "             sample_count  oos_r2_gkx  resid_mean  resid_std\n",
      "size_bucket                                                 \n",
      "1_Small            525780   -0.000198    0.012400   0.265881\n",
      "2_Small-Mid        525551   -0.000191    0.005732   0.181501\n",
      "3_Mid              525542   -0.000259    0.005713   0.155752\n",
      "4_Mid-Large        525551   -0.000375    0.006701   0.140489\n",
      "5_Large            525706   -0.000614    0.007162   0.113585\n",
      "规模分组分析图已保存至 results/q7_diagnostics/size_bucket_analysis.png\n"
     ]
    }
   ],
   "source": [
    "analyze_size_buckets(df_test, resid_test, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6327c089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 过拟合特征检验（Val vs Test） ===\n",
      "验证集36个月滚动平均R²: -0.000577\n",
      "测试集36个月滚动平均R²: -0.000344\n",
      "Val - Test R²差值: -0.000233\n",
      "是否过拟合: 否（差值>0.2%为过拟合）\n",
      "过拟合检验图已保存至 results/q7_diagnostics/overfit_test.png\n"
     ]
    }
   ],
   "source": [
    "check_overfit(resid_val, y_val, resid_test, y_test, df_val, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ecd8a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 弹性网络调优尝试 ===\n",
      "调优参数: l1_ratio=0.5 (固定), alpha 候选: [0.01, 0.1, 0.5, 1.0, 5.0]\n",
      "  alpha= 0.01: Val R²=0.002134, Test R²=-0.002638, 残差标准差=0.179539\n",
      "  alpha= 0.10: Val R²=-0.000548, Test R²=-0.000262, 残差标准差=0.179207\n",
      "  alpha= 0.50: Val R²=-0.000548, Test R²=-0.000262, 残差标准差=0.179207\n",
      "  alpha= 1.00: Val R²=-0.000548, Test R²=-0.000262, 残差标准差=0.179207\n",
      "  alpha= 5.00: Val R²=-0.000548, Test R²=-0.000262, 残差标准差=0.179207\n",
      "\n",
      "最佳调优参数 (基于 Val R²): alpha=0.01, l1_ratio=0.5\n",
      "最佳参数的 *验证集* 性能: Val R²=0.002134\n",
      "最佳参数的 *测试集* 性能: Test R²=-0.002638, 残差标准差=0.179539\n",
      "调优结果已保存至 results/q7_diagnostics/elastic_net_tuning_results.csv\n"
     ]
    }
   ],
   "source": [
    "tuning_df = tuning_elastic_net(df, X, y, scaler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GKX",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
